{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os, sys\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torchvision as tv\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from model.detr import DETR\n",
    "from dataset import COCODataModule, coco_labels\n",
    "\n",
    "from loss.losses import DETR_Losses\n",
    "\n",
    "pl.seed_everything(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "hidden_dim = 512\n",
    "num_epochs = 100\n",
    "num_classes = len(coco_labels)\n",
    "num_queries = 100\n",
    "learning_rate = 1e-4\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "dtype = torch.bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for elem in train_dl:\n",
    "#     images, targets, num_boxes = elem\n",
    "#     imgs = images.permute(0, 2, 3, 1).numpy()\n",
    "#     targs = targets.numpy()\n",
    "#     n_boxes = num_boxes.numpy()\n",
    "    \n",
    "#     for batch_ind in range(imgs.shape[0]):\n",
    "#         img = (imgs[batch_ind] * 255.).astype(np.uint8)\n",
    "#         targ = targs[batch_ind]\n",
    "#         n_box = n_boxes[batch_ind][0]\n",
    "        \n",
    "#         valid_targ = targ[:n_box]\n",
    "        \n",
    "#         h, w = img.shape[:2]\n",
    "        \n",
    "#         image_size = np.array([w, h, w, h])\n",
    "        \n",
    "#         for box in valid_targ:\n",
    "#             label_ind = box[4].astype(np.int32)\n",
    "#             label = coco_labels[label_ind-1]\n",
    "#             box = box[:4]\n",
    "            \n",
    "#             box = (box * image_size).astype(np.int32)\n",
    "#             x0, y0, x1, y1 = box\n",
    "            \n",
    "#             color = (36, 255, 12)\n",
    "#             img = cv2.rectangle( img.copy(), (int(x0), int(y0)), (int(x1), int(y1)), color, int(2) )\n",
    "#             cv2.putText(img, label, (box[0], max(10, box[1]-10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "            \n",
    "#         plt.imshow(img)\n",
    "#         plt.show()\n",
    "#     print(imgs.shape, targs.shape, n_boxes.shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DETR_ObjectDetector(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, num_classes=num_classes, num_queries = num_queries, hidden_dim=hidden_dim,\n",
    "                    batch_size=4, lr=1e-4, lr_backbone=1e-5,weight_decay=1e-4, lr_drop=200, image_size=256,\n",
    "                    clip_max_norm=0.1):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.detr = DETR(num_classes=self.hparams.num_classes, num_queries = self.hparams.num_queries, hidden_dim=self.hparams.hidden_dim)\n",
    "        self.detr_loss = DETR_Losses(num_classes = self.hparams.num_classes, ce_weight=1., bbox_weight=5., giou_weight=2., eos_coef=0.1)\n",
    "    \n",
    "    def forward(self, images):\n",
    "        return self.detr(images)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        all_backbone_params = []\n",
    "        other_params = []\n",
    "        for name, param in self.detr.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'backbone' in name:\n",
    "                    all_backbone_params.append(param)\n",
    "                else:\n",
    "                    other_params.append(param)\n",
    "        \n",
    "        param_dicts = [\n",
    "            {\"params\": other_params},\n",
    "            {\n",
    "                \"params\": all_backbone_params,\n",
    "                \"lr\": self.hparams.lr_backbone,\n",
    "            },\n",
    "        ]\n",
    "        \n",
    "        optimizer = torch.optim.Adam(param_dicts, lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=self.hparams.lr_drop, gamma=0.1)\n",
    "        return {\n",
    "            'optimizer': optimizer, \n",
    "            'lr_scheduler': lr_scheduler\n",
    "        }\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, targets, num_boxes = batch\n",
    "        out = self(images)\n",
    "        prepped_targets = self.detr_loss.prep_gt(targets, num_boxes)\n",
    "        loss_dict = self.detr_loss(out, prepped_targets)\n",
    "        \n",
    "        total_loss = (loss_dict['class_loss'] * self.detr_loss.hparams.ce_weight) + \\\n",
    "                     (loss_dict['bbox_loss' ] * self.detr_loss.hparams.bbox_weight) + \\\n",
    "                     (loss_dict['giou_loss' ] * self.detr_loss.hparams.giou_weight)\n",
    "        \n",
    "        top_k_accuracy_logs = {}\n",
    "        for i, k in enumerate(self.detr_loss.hparams.topk):\n",
    "            top_k_accuracy_logs[f\"top_{k}_accuracy\"] = loss_dict['accuracy'][i]\n",
    "            \n",
    "        self.log(\n",
    "            \"train_performance\", \n",
    "            top_k_accuracy_logs,\n",
    "            on_step=True,\n",
    "            on_epoch=True\n",
    "        )\n",
    "        \n",
    "        self.log(\n",
    "            \"train_loss\", {\n",
    "            'class_loss': loss_dict['class_loss'],\n",
    "            'bbox_loss': loss_dict['bbox_loss' ],\n",
    "            'giou_loss': loss_dict['giou_loss' ],\n",
    "            'total_loss': total_loss\n",
    "            },\n",
    "            on_step=True,\n",
    "            on_epoch=True\n",
    "        )\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, targets, num_boxes = batch\n",
    "        out = self(images)\n",
    "        prepped_targets = self.detr_loss.prep_gt(targets, num_boxes)\n",
    "        loss_dict = self.detr_loss(out, prepped_targets)\n",
    "        \n",
    "        total_loss = (loss_dict['class_loss'] * self.detr_loss.hparams.ce_weight) + \\\n",
    "                     (loss_dict['bbox_loss' ] * self.detr_loss.hparams.bbox_weight) + \\\n",
    "                     (loss_dict['giou_loss' ] * self.detr_loss.hparams.giou_weight)\n",
    "        \n",
    "        top_k_accuracy_logs = {}\n",
    "        for i, k in enumerate(self.detr_loss.hparams.topk):\n",
    "            top_k_accuracy_logs[f\"top_{k}_accuracy\"] = loss_dict['accuracy'][i]\n",
    "            \n",
    "        self.log(\n",
    "            \"val_performance\", \n",
    "            top_k_accuracy_logs,\n",
    "            on_step=True,\n",
    "            on_epoch=True\n",
    "        )\n",
    "        \n",
    "        self.log(\n",
    "            \"val_loss\", {\n",
    "            'class_loss': loss_dict['class_loss'],\n",
    "            'bbox_loss': loss_dict['bbox_loss' ],\n",
    "            'giou_loss': loss_dict['giou_loss' ],\n",
    "            'total_loss': total_loss\n",
    "            },\n",
    "            on_step=True,\n",
    "            on_epoch=True                 \n",
    "        )\n",
    "        \n",
    "        self.log(\n",
    "            \"total_val_loss\", \n",
    "            total_loss,\n",
    "            on_epoch=True\n",
    "        )\n",
    "        \n",
    "        return total_loss\n",
    "    \n",
    "    ###############\n",
    "    # Data stuff! #\n",
    "    ###############\n",
    "    \n",
    "    def prepare_data(self):\n",
    "        self.coco_data_module = COCODataModule(image_size=self.hparams.image_size)\n",
    "        \n",
    "    def setup(self, stage=None):\n",
    "        self.coco_data_module.setup()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dl = self.coco_data_module.train_dataloader(batch_size=self.hparams.batch_size)\n",
    "        return train_dl\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        val_dl = self.coco_data_module.val_dataloader(batch_size=self.hparams.batch_size)\n",
    "        return val_dl\n",
    "    \n",
    "    \n",
    "\n",
    "detr = DETR_ObjectDetector(num_classes=num_classes, num_queries = num_queries, hidden_dim=hidden_dim)\n",
    "detr.configure_optimizers()\n",
    "detr.load_from_checkpoint(checkpoint_path=\"Final_Checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    default_root_dir=  os.path.join( os.getcwd(), 'model_artifacts/'),\n",
    "    gpus = 1,\n",
    "    max_epochs = 500,\n",
    "    callbacks=[\n",
    "        pl.callbacks.ModelCheckpoint(monitor='total_val_loss',save_top_k=3, mode='min'),\n",
    "        pl.callbacks.StochasticWeightAveraging(swa_lrs=1e-2)\n",
    "    ],\n",
    "    gradient_clip_val = detr.hparams.clip_max_norm,\n",
    "    gradient_clip_algorithm='norm',\n",
    "    auto_scale_batch_size=\"power\",\n",
    "    precision='bf16',\n",
    "    log_every_n_steps=50,\n",
    "    benchmark=True,\n",
    "    accumulate_grad_batches=10\n",
    ")\n",
    "#trainer.logger._log_graph = True\n",
    "trainer.logger._default_hp_metric = None\n",
    "\n",
    "#tuner = pl.tuner.tuning.Tuner(trainer)\n",
    "\n",
    "#new_batch_size = tuner.scale_batch_size(detr)\n",
    "\n",
    "detr.hparams.batch_size = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(detr)\n",
    "trainer.save_checkpoint(\"Final_Checkpoint.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
